# 高级提示工程技术（Advanced Prompting Techniques）

## 文档概述
- **来源**：Jimmy Song的《Agentic Design Patterns》附录A。
- **主题**：介绍如何通过精心设计的提示（Prompt）优化语言模型（LLM）的交互，提升AI系统的性能、可靠性和创造性。
- **目标读者**：AI开发者、智能体系统设计师。
- **文档结构**：从基础原则到高级技术，包含示例和最佳实践。
- **更新日期**：基于网页内容（假设为最新版本）。

## 1. 提示工程简介
提示工程是与LLM交互的核心方法，通过输入设计引导模型生成期望输出。好的提示能最大化模型潜力，坏的提示会导致模糊或错误响应。

- **关键目标**：
  - 获得准确、相关且富有创造性的回复。
  - 适用于简单聊天到复杂多智能体系统。
- **重要性**：提示工程是一门迭代技能，需要理解模型的能力与局限，并有效传达意图。

## 2. 核心提示原则
设计提示时遵循以下原则，以提升效果：

- **清晰与具体**：指令必须明确，避免歧义。指定任务、输出格式和限制。
  - 示例：不要说“想想这个”，而是说“总结以下文本：\[文本\]”。
- **简洁**：保持提示简明，避免冗余或复杂句式。
- **动词使用**：使用动作动词如“Act as”（扮演）、“Analyze”（分析）、“Summarize”（总结）等。
- **正面指令优于约束**：强调期望行为，而不是“不做某事”。负面约束仅用于安全或格式要求。
- **实验与迭代**：通过测试和优化找到最佳提示。

## 3. 基础提示技术
这些是入门级技术，依赖模型的预训练知识。

- **零样本提示（Zero-Shot Prompting）**：仅提供任务描述，无示例。
  - 适用场景：简单任务如翻译或问答。
  - 示例：
    ```
    将以下英文句子翻译成中文：Hello, world.
    ```
    预期输出：你好，世界。

- **单样本提示（One-Shot Prompting）**：提供一个示例，帮助模型理解模式。
  - 适用场景：需要特定格式的任务。
  - 示例：
    ```
    输入：苹果是水果。
    输出：分类 = 水果。
    
    输入：狗是动物。
    输出：
    ```
    预期输出：分类 = 动物。

- **少样本提示（Few-Shot Prompting）**：提供多个示例，引导模型学习模式。
  - 适用场景：复杂任务，如分类或生成。
  - 示例：
    ```
    示例1：文本 = "我爱这部电影！" 输出 = 正面情感。
    示例2：文本 = "太失望了。" 输出 = 负面情感。
    
    文本 = "还行吧。" 输出 =
    ```
    预期输出：中性情感。

## 4. 提示结构化
通过结构化提升提示的清晰度和效果。

- **系统提示（System Prompting）**：在开头定义模型的角色、规则或上下文。
  - 示例：`你是一个专业的AI助手，必须以JSON格式输出。`

- **角色提示（Role Prompting）**：让模型扮演特定角色。
  - 示例：`作为一个数学老师，解释这个方程：E=mc²。`

- **分隔符使用**：使用如`###`或`"""`分隔提示部分。
  - 示例：
    ```
    ### 指令 ###
    总结文本。
    
    ### 文本 ###
    [插入文本]
    ```

- **上下文工程**：提供相关背景信息。
- **结构化输出**：指定输出格式，如JSON或列表。
  - 示例：`输出格式：{"summary": "摘要", "key_points": ["点1", "点2"]}`

## 5. 推理与思考过程技术
这些技术鼓励模型逐步思考，提高复杂任务的准确性。

- **思维链（Chain of Thought, CoT）**：添加“Let’s think step by step”来引导逐步推理。
  - 适用场景：数学或逻辑问题。
  - 示例：
    ```
    问题：如果A比B大2，B比C大3，A=10，那么C是多少？
    逐步思考：
    ```
    预期：A=10 → B=8 → C=5。

- **自洽性（Self-Consistency）**：生成多个推理路径，选择最一致的。
  - 适用场景：不确定任务，通过投票提升鲁棒性。

- **反思提示（Step-Back Prompting）**：让模型反思自己的响应。
  - 示例：`检查你的答案是否正确，并改进。`

- **思维树（Tree of Thoughts, ToT）**：探索多个推理分支，如决策树。
  - 适用场景：复杂规划任务。

## 6. 行动与交互技术
这些技术涉及模型与外部世界的交互。

- **工具使用 / 函数调用**：让模型调用外部工具或API。
  - 适用场景：需要实时数据或计算的任务。

- **ReAct (Reason & Act)**：结合推理（Reason）和行动（Act），循环执行直到任务完成。
  - 适用场景：动态交互，如智能体系统。
  - 示例流程：Think → Act → Observe → Repeat。

## 7. 高级技术
这些是更复杂的优化方法。

- **自动提示工程（APE）**：使用LLM自动生成或优化提示。
- **迭代提示 / 精炼**：基于反馈逐步改进。
- **负面示例**：提供错误示例来避免常见问题。
- **类比使用**：用类比引导模型理解抽象概念。
- **分解认知 / 任务拆分**：将大任务拆分成小步骤。
- **检索增强生成（RAG）**：结合外部知识检索，提升事实准确性。
- **用户画像模式（Persona Pattern）**：基于用户画像定制响应。
- **Google Gems 使用**：利用特定工具或框架优化提示。
- **用 LLM 优化提示（元方法）**：让模型自我优化。
- **特定任务提示**：如代码生成或多模态提示（处理图像/文本）。

## 8. 最佳实践与实验
- **总结**：结合多种技术，迭代测试。记录过程以改进。
- **实验建议**：
  - 从小样本开始，逐步添加复杂性。
  - 考虑模型参数（如温度：低温度更确定，高温度更创意）。
  - 测试不同LLM（如GPT系列）的效果差异。
- **常见陷阱**：避免过长提示、忽略模型局限（如幻觉问题）。
- **参考资源**：
  - Chain-of-Thought论文（Wei et al., 2022）。
  - ReAct论文（Yao et al., 2022）。
  - 其他：Prompt Engineering Guide网站。

## 附录：提示工程模板示例
- **通用模板**：
  ```
  [角色]：你是一个[具体角色]。
  [任务]：执行[具体任务]。
  [上下文]：[提供背景]。
  [示例]：[可选示例]。
  [输出格式]：[指定格式]。
  ```
